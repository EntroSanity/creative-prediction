---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
---

### Tutorial Description

The goal of this tutorial is to apply predictive machine learning models to creative data. The focus of the tutorial will be recurrent neural networks (RNNs), deep learning models that can be used to generate sequential and temporal data. RNNs can be applied to many kinds of creative data including text and music. They can learn the long-range structure from a corpus of data and "create" new sequences by predicting one element at a time. When embedded in a creative interface, they can be used for "predictive interaction" where a human collaborates with, influences, and is influenced by a generative neural network.

We will walk through the fundamental steps for training creative RNNs with the participants using live-coded demonstrations with Python code in Jupyter Notebooks. These steps are: collecting and cleaning data, building and training an RNN, and developing predictive interactions.

Our demonstrations will be motivated from examples from our own research in creativity support tools. We will show how streams of interaction data from a creative musical interface can be modelled with deep recurrent neural networks (RNNs). From this data, we can predict users' future interactions, or the potential interactions of other users. This enables us to "fill in" parts of a iPad-based musical ensemble when other users are not available, or to continue a user's composition with new musical layers. 

This session will be interactive. The participants will be provided with demonstration code at the beginning of the session that they can run on their laptops as we go. Instructions will be provided prior to the tutorial so that participants can setup their systems. We will also have live demonstrations and interactive live-hacking of our creative RNN systems, including RoboJam: a agent for responding to smartphone musical performances, the Neural iPad Ensemble, and the Neural Lever Machine - a physical computing interface to a creative RNN. 

We think that every participant will come out of the tutorial with a custom RNN trained on text or musical data, as well as inspiration to make new creative neural network systems!

### Session Plan

- **Introduction to Predictive Interaction (30 minutes)**
- - Overview of Deep Learning and Creativity.
- - What is a Recurrent Neural Network?
- - Sequence learning, classification, and training
- - Temporal and non-temporal models.
- - Forward models and bio-inspired prediction.
- **Generating Creative Sequences (60 minutes)**
- - RNNs and Long Short-Term Memory (LSTM) with Keras and Python.
- - Generating Text with a CharRNN; inventing Star Trek episode titles.
- - Continuing musical sequences.
- **Interacting with RNNs (30 minutes)**
- - Introduction to the Neural iPad Ensemble, and Robojam, two projects showing how RNNs can be used in interactive - creativity systems.
- - Time for demonstration, interaction, and live-hacking with these systems.

### Presenters

#### Dr. Charles Martin

Charles Martin is an expert in music technology, musical AI, and human computer interaction. His work involves applying ML to creative data to help enhance users’ creativity and enjoyment. Charles is currently a postdoctoral fellow at the University of Oslo working in creative machine learning systems. He holds a PhD in computer science (2016, Australian National Unversity), a masters degree in percussion performance (2012, Luleå University of Technology), and a bachelor’s degree in mathematics (2008). He has performed his own music in Australia, the USA and across Europe, and released several musical apps for iOS devices. Charles’ recent projects include a Neural Network-controlled iPad Ensemble, and RoboJam, a deep learning system that collaborates with smartphone music makers.

#### Assoc. Prof. Kyrre Glette

Kyrre Glette received his M.Sc. in Computer Engineering (2004) from the Norwegian University of Science and Technology, Norway, and his Ph.D. in Computer Science (2008) from the University of Oslo, Norway. He is currently employed at the University of Oslo as an Associate Professor. His research interests are intelligent, adaptive, and biologically inspired systems, with a focus on embedded and runtime evolvable hardware systems. Another research interest is evolutionary robotics with an emphasis on simulation, design and prototyping of biologically inspired robots. 

#### Prof. Jim Tørresen

Jim Tørresen is the leader of the Robotics and Intelligent Systems group at the University of Oslo’s Department of Informatics where he has served as professor since 1999. He is an expert in bio-inspired computing, machine learning, reconfigurable hardware, robotics and applying these to complex real-world applications. Jim Torresen was a visiting researcher at Kyoto University, Japan in 1993, at Electrotechnical laboratory, Tsukuba, Japan in 1997 and a visiting professor at Cornell University, USA in 2010. He has published more than 150 scientific papers in international journals, books and conference proceedings and is currently principal investigator in four projects funded by the Research Council of Norway.
