---
layout: reveal-larger
title: Creative Prediction Projects
permalink: /presentations/creprepro/
---

{% include slides/title.html %}

<section data-markdown>
<textarea data-template>
## Creative Predictions

![]({{site.baseurl}}/assets/creative-prediction-image.png) <!-- .element: width="100%"-->

</textarea>
</section>

<section data-markdown>
<textarea data-template>
## Learning to Predict Sequences

![]({{site.baseurl}}/assets/sequence-learning.png) <!-- .element: width="100%"-->

</textarea>
</section>

<section data-markdown>
<textarea data-template>

## Melody to Harmony in MicroJam

![]({{site.baseurl}}/assets/robojam-interaction.png) <!-- .element: width="50%"; float="right"-->

1. Gain an overview of current deep learning techniques for music generation.
2. Develop a melody to harmony sequence to sequence model
3. Train the model on matched melody/harmony sequences (e.g., from the Lakh music dataset)
4. Use MicroJam-sourced data as input and see if the generated harmonies make sense!

</textarea>
</section>

<section data-markdown>
<textarea data-template>

## Seq-to-Seq Music Generation

![](https://magenta.tensorflow.org/assets/music_transformer/motifs_shaded_boxes.png) <!-- .element: width="50%" float="right"-->

- Read and understand the techniques behind the Transformer architecture.
- Implement your own Transformer 
- Find a musical dataset with matched sequences to try to generate
- Train your model, listen to the results and find a way to evaluate them.

</textarea>
</section>

<section data-markdown>
<textarea data-template>

## Generating colour-palettes from audio data

![]({{site.baseurl}}/assets/nainoa-shizuru-NcdG9mK3PBY-unsplash.jpg) <!-- .element: width="50%" float="right" -->

1. Gain an overview of audio processing techniques used with neural networks.
2. Obtain a dataset of audio and video (or colour) data.
3. Try different neural network designs and evaluate the results. Even a simple fully-connected ANN might work well!

</textarea>
</section>


<section data-markdown>
<textarea data-template>

## Motion-to-Motion Generators

![]({{site.baseurl}}/assets/motion-to-motion.png) <!-- .element: width="80%" -->

1. Gain an overview of the main DL methods used for motion generation including RNNs, MDRNNs, and world models.
2. Find a dataset of motion capture or other movement data (or capture one yourself!)
3. Train the ANN and evaluate its generative abilities.

</textarea>
</section>
