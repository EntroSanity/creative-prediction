---
layout: reveal
title:  Mixture Density Networks
permalink: /presentations/mixture-density-networks/
---

<section id="title-slide">
  <h1 class="title">Mixture Density Networks</h1>
  <p class="author">Charles Martin</p>
</section>

<section class="slide level2">
<h3 id="so-far-rnns-that-model-categorical-data">So far; RNNs that Model Categorical Data</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment">Remember that most RNNs (and most deep learning models) end with a softmax layer.</li>
<li class="fragment">This layer outputs a probability distribution for a set of categorical predictions.</li>
<li class="fragment">E.g.:
<ul>
<li class="fragment">image labels,</li>
<li class="fragment">letters, words,</li>
<li class="fragment">musical notes,</li>
<li class="fragment">robot commands,</li>
<li class="fragment">moves in chess.</li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./charRNN-arch.png" style="width:95.0%" /> <img data-src="./charRNN-training.png" style="width:80.0%" /></p>
</div>
</div>
</section>

<section class="slide level2">
<h3 id="expressive-data-is-often-continuous">Expressive Data is Often Continuous</h3>
<div class="columns">
<div class="column">
<p><img data-src="./music-interface-1.jpg" style="width:60.0%" /> <img data-src="./music-interface-2.png" style="width:60.0%" /></p>
</div><div class="column">
  <p><img data-src="./music-interface-3.jpg" style="width:60.0%" />
    <iframe src="https://giphy.com/embed/1AjE1Ci6w3w6fv4D2z" width="480" height="480" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="so-are-bio-signals">So are Bio-Signals</h3>
<div class="columns">
<div class="column">
<p><img data-src="./continuous-data-ecg.png" style="width:60.0%" /></p>
</div><div class="column">
<p><img data-src="./continuous-data-eeg.png" style="width:60.0%" /> <img data-src="./continuous-data-music.png" style="width:60.0%" /></p>
</div>
</div>
<p>Image Credit: Wikimedia</p>
</section>

<section class="slide level2">
<h3 id="categorical-vs.continuous-models">Categorical vs.¬†Continuous Models</h3>
<div class="columns">
<div class="column">
<p><img data-src="./categorical_plot.png" /></p>
</div><div class="column">
<p><img data-src="./mixture_plot.png" /></p>
</div>
</div>
</section>

<section class="slide level2">
<h3 id="normal-gaussian-distribution">Normal (Gaussian) Distribution</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment">‚ÄúStandard‚Äù probability distribution</li>
<li class="fragment">Has two parameters:
<ul>
<li class="fragment">mean (<span class="math inline">\(\mu\)</span>) and</li>
<li class="fragment">standard deviation (<span class="math inline">\(\sigma\)</span>)</li>
</ul></li>
<li class="fragment">Probability Density Function:
<ul>
<li class="fragment"><span class="math display">\[\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2} } e^{ -\frac{(x-\mu)^2}{2\sigma^2} }\]</span></li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./normal_distribution_mu0_sd5.png" style="width:100.0%" /></p>
</div>
</div>
</section>

<section class="slide level2">
<h3 id="problem-normal-distribution-might-not-fit-data">Problem: Normal distribution might not fit data</h3>
<div class="columns">
<div class="column">
<p>What if the data is complicated?</p>
<ul>
<li class="fragment">It‚Äôs easy to ‚Äúfit‚Äù a normal model to any data.
<ul>
<li class="fragment">Just calculate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li class="fragment">But this might not fit the data well.</li>
</ul>
</div><div class="column">
<p><img data-src="./complex_distribution_hist_and_normal.png" style="width:100.0%" /></p>
</div>
</div>
</section>

<section class="slide level2">

<h3 id="mixture-of-normals">Mixture of Normals</h3>
<div class="columns">
<div class="column">
<p>Three groups of parameters:</p>
<ul>
<li class="fragment">means (<span class="math inline">\(\boldsymbol\mu\)</span>): location of each component</li>
<li class="fragment">standard deviations (<span class="math inline">\(\boldsymbol\sigma\)</span>): width of each component</li>
<li class="fragment">Weight (<span class="math inline">\(\boldsymbol\pi\)</span>): height of each curve</li>
<li class="fragment">Probability Density Function:
<ul>
<li class="fragment"><span class="math display">\[p(x) = \sum_{i=1}^K \pi_i\mathcal{N}(x \mid \mu, \sigma^2)\]</span></li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./complex_mixture.png" style="width:100.0%" /></p>
</div>
</div>
</section>

<section class="slide level2">

<h3 id="this-solves-our-problem">This solves our problem:</h3>
<div class="columns">
<div class="column">
<p>Returning to our modelling problem, let‚Äôs plot the PDF of a evenly-weighted mixture of the two sample normal models.</p>
<p>We set:</p>
<ul>
<li class="fragment"><span class="math inline">\(K = 2\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\pi = [0.5, 0.5]\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\mu = [-5, 5]\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\sigma = [2, 3]\)</span></li>
<li class="fragment">(bold used to indicate the vector of parameters for each component)</li>
</ul>
<p>In this case, I knew the right parameters, but normally you would have to <em>estimate</em>, or <em>learn</em>, these somehow‚Ä¶</p>
</div><div class="column">
<p><img data-src="./complex_distribution_hist_and_mixture.png" style="width:100.0%" /></p>
</div>
</div>
</section>

<section id="mixture-density-networks" class="slide level2">
<h2>Mixture Density Networks</h2>
<p><img data-src="./mse-network-normal.png" /></p>
<ul>
<li class="fragment">Neural networks used to model complicated real-valued data.
<ul>
<li class="fragment">i.e., data that might not be very ‚Äúnormal‚Äù</li>
</ul></li>
<li class="fragment">Usual approach: use a neuron with linear activation to make predictions.
<ul>
<li class="fragment">Training function could be MSE (mean squared error).</li>
</ul></li>
<li class="fragment">Problem! This is equivalent to fitting to a single normal model! üò±</li>
<li class="fragment">(See Bishop, C (1994) for proof and more details)</li>
</ul>
</section>
<section id="mixture-density-networks-1" class="slide level2">
<h2>Mixture Density Networks</h2>
<p><img data-src="./mdn-network.png" /></p>
<ul>
<li class="fragment">Idea: output parameters of a mixture model instead!</li>
<li class="fragment">Rather than MSE for training, use the PDF of the mixture model.</li>
<li class="fragment">Now network can model complicated distributions! üòå</li>
</ul>
</section>

<section id="simple-example-in-keras" class="slide level2">
<h2>Simple Example in Keras</h2>
<p><img data-src="./arcsine-function.png" style="width:30.0%" /></p>
<ul>
<li class="fragment">Difficult data is not hard to find! Think about modelling an inverse sine (arcsine) function.
<ul>
<li class="fragment">Each input value takes multiple outputs‚Ä¶</li>
<li class="fragment">This is not going to go well for a single normal model.</li>
</ul></li>
</ul>
</section>

<section data-markdown>
<textarea data-template>
<h3 id="feedforward-mse-network">Feedforward MSE Network</h3>
  
<p><img data-src="./arcsine-feedforward-mse-prediction.png" style="width:30.0%" /> <img data-src="./feedforward-mse-prediction-loss-plot.png" style="width:40.0%" /></p>

Here's a simple two-hidden-layer network (286 parameters), trained to produce the above result.

<pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
model = Sequential()
model.add(Dense(15, batch_input_shape=(None, 1), activation='tanh'))
model.add(Dense(15, activation='tanh'))
model.add(Dense(1, activation='linear'))
model.compile(loss='mse', optimizer='rmsprop')
model.fit(x=x_data, y=y_data, batch_size=128, epochs=200, validation_split=0.15)
</code></pre>

</textarea>
</section>

<section id="mdn-architecture" class="slide level2">
<h2>MDN Architecture:</h2>
<p><img data-src="./mdn-network.png" /></p>
<ul>
<li class="fragment">Loss function for MDN is negative log of likelihood function <span class="math inline">\(\mathcal{L}\)</span>.</li>
<li class="fragment"><span class="math inline">\(\mathcal{L}\)</span> measures likelihood of <span class="math inline">\(t\)</span> being drawn from a mixture parametrised by <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(\pi\)</span> which are generated by the network inputs <span class="math inline">\(x\)</span>:</li>
</ul>
<p><span class="math display">\[\mathcal{L} = \sum_{i=1}^K\pi_i(\mathbf{x})\mathcal{N}\bigl(\mu_i(\mathbf{x}), \sigma_i^2(\mathbf{x}); \mathbf{t} \bigr)\]</span></p>
</section>

<section class="slide level2">

<h3 id="feedforward-mdn-solution">Feedforward MDN Solution</h3>
<p><img data-src="./arcsine-feedforward-mdn-predictions.png" style="width:30.0%" /> <img data-src="./arcsine-feedforward-mdn-loss.png" style="width:40.0%" /></p>
<p>And, here‚Äôs a simple two-hidden-layer MDN (510 parameters), that achieves the above result! Much better!</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
N_MIXES = 5

model = Sequential()
model.add(Dense(15, batch_input_shape=(None, 1), activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(mdn.MDN(1, N_MIXES)) # here's the MDN layer!
model.compile(loss=mdn.get_mixture_loss_func(1,N_MIXES), optimizer='rmsprop')
model.summary()
</code></pre></div>
</section>

<section class="slide level2">

<h3 id="getting-inside-the-mdn-layer">Getting inside the MDN layer</h3>
<p>Here‚Äôs the same network wihtout using the MDN layer abstraction (this is with Keras‚Äô functional API):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
def elu_plus_one_plus_epsilon(x):
    """ELU activation with a very small addition to help prevent NaN in loss."""
    return (K.elu(x) + 1 + 1e-8)

N_HIDDEN = 15
N_MIXES = 5

inputs = Input(shape=(1,), name='inputs')
hidden1 = Dense(N_HIDDEN, activation='relu', name='hidden1')(inputs)
hidden2 = Dense(N_HIDDEN, activation='relu', name='hidden2')(hidden1)

mdn_mus = Dense(N_MIXES, name='mdn_mus')(hidden2)
mdn_sigmas = Dense(N_MIXES, activation=elu_plus_one_plus_epsilon, name='mdn_sigmas')(hidden2)
mdn_pi = Dense(N_MIXES, name='mdn_pi')(hidden2)

mdn_out = Concatenate(name='mdn_outputs')([mdn_mus, mdn_sigmas, mdn_pi])

model = Model(inputs=inputs, outputs=mdn_out)
model.summary()
</code></pre></div>
</section>

<section id="loss-function-the-tricky-bit." class="slide level2">
<h2>Loss Function: The Tricky Bit.</h2>
<p>Loss function for the MDN should be the negative log likelihood:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
def mdn_loss(y_true, y_pred):
    # Split the inputs into paramaters
    out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[N_MIXES, N_MIXES, N_MIXES],
                                         axis=-1, name='mdn_coef_split')
    mus = tf.split(out_mu, num_or_size_splits=N_MIXES, axis=1)
    sigs = tf.split(out_sigma, num_or_size_splits=N_MIXES, axis=1)
    # Construct the mixture models
    cat = tfd.Categorical(logits=out_pi)
    coll = [tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale
            in zip(mus, sigs)]
    mixture = tfd.Mixture(cat=cat, components=coll)
    # Calculate the loss function
    loss = mixture.log_prob(y_true)
    loss = tf.negative(loss)
    loss = tf.reduce_mean(loss)
    return loss

model.compile(loss=mdn_loss, optimizer='rmsprop')
</code></pre></div>
<p>Let‚Äôs go through bit by bit‚Ä¶</p>
</section>

<section id="loss-function-part-1" class="slide level2">
<h2>Loss Function: Part 1:</h2>
<p>First we have to extract the mixture paramaters.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
# Split the inputs into paramaters
out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[N_MIXES, N_MIXES, N_MIXES],
                                     axis=-1, name='mdn_coef_split')
mus = tf.split(out_mu, num_or_size_splits=N_MIXES, axis=1)
sigs = tf.split(out_sigma, num_or_size_splits=N_MIXES, axis=1)
</code></pre></div>
<ul>
<li class="fragment">Split up the parameters <span class="math inline">\(\boldsymbol\mu\)</span>, <span class="math inline">\(\boldsymbol\sigma\)</span>, and <span class="math inline">\(\boldsymbol\pi\)</span>, remember that there are N_MIXES <span class="math inline">\(= K\)</span> of each of these.</li>
<li class="fragment"><span class="math inline">\(\boldsymbol\mu\)</span> and <span class="math inline">\(\boldsymbol\sigma\)</span> have to be split <em>again</em> so that we can iterate over them (you can‚Äôt iterate over an axis of a tensor‚Ä¶)</li>
</ul>
</section>

<section id="loss-function-part-2" class="slide level2">
<h2>Loss Function: Part 2:</h2>
<p>Now we have to construct the mixture model‚Äôs PDF.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
# Construct the mixture models
cat = tfd.Categorical(logits=out_pi) 
coll = [tfd.Normal(loc=loc, scale=scale) for loc, scale
        in zip(mus, sigs)]
mixture = tfd.Mixture(cat=cat, components=coll)
</code></pre></div>
<ul>
<li class="fragment">For this, we‚Äôre using the <code>Mixture</code> abstraction provided in <code>tensorflow-probability.distributions</code>.</li>
<li class="fragment">This takes a categorical (a.k.a. softmax, a.k.a. generalized Bernoulli distribution) model, and a list the component distributions.</li>
<li class="fragment">Each normal PDF is contructed using <code>tfd.Normal</code>.</li>
<li class="fragment">Can do this from first principles as well, but good to use abstractions that are available (?)</li>
</ul>
</section>

<section id="loss-function-part-3" class="slide level2">
<h2>Loss Function: Part 3:</h2>
<p>Finally, we calculate the loss:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python">
loss = mixture.log_prob(y_true)
loss = tf.negative(loss)
loss = tf.reduce_mean(loss)
</code></pre></div>
<ul>
<li class="fragment"><code>mixture.log_prob(y_true)</code> means ‚Äúthe log-likelihood of sampling <code>y_true</code> from the distribution called <code>mixture</code>.‚Äù</li>
</ul>
</section>

<section id="some-more-details." class="slide level2">
<h2>Some more details‚Ä¶.</h2>
<p><img data-src="./MultivariateNormal.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">This ‚Äúversion‚Äù of a mixture model works for a mixture of 1D normal distributions.</li>
<li class="fragment">Not too hard to extend to multivariate normal distributions, which are useful for lots of problems.</li>
<li class="fragment">This is how it actually works in my Keras MDN layer, <a href="https://github.com/cpmpercussion/keras-mdn-layer/">have a look at the code for more details‚Ä¶</a></li>
</ul>
</section>

<section id="mdn-rnns" class="slide level2">
<h2>MDN-RNNs</h2>
<p><img data-src="mdn-rnn-movement-example.png" /></p>
<p>MDNs can be handy at the end of an RNN! Imagine a robot calculating moves forward through space, it might have to choose from a number of valid positions, each of which could be modelled by a 2D Normal model.</p>
</section>

<section id="mdn-rnn-architecture" class="slide level2">
<h2>MDN-RNN Architecture</h2>
<p><img data-src="mdn-rnn-architecture-simple.png" /></p>
<p>Can be as simple as putting an MDN layer after recurrent layers!</p>
</section>
<section id="use-cases-handwriting-generation" class="slide level2">
<h2>Use Cases: Handwriting Generation</h2>
<p><img data-src="graves-handwriting-generation.png" style="width:40.0%" /> <img data-src="graves-handwriting2.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">Handwriting Generation RNN (Graves, 2013).</li>
<li class="fragment">Trained on handwriting data.</li>
<li class="fragment">Predicts the next location of the pen (<span class="math inline">\(dx\)</span>, <span class="math inline">\(dy\)</span>, and up/down)</li>
<li class="fragment">Network takes text to write as an extra input, RNN learns to decide what character to write next.</li>
</ul>
</section>

<section id="use-cases-sketchrnn" class="slide level2">
<h2>Use Cases: SketchRNN</h2>
<p><img data-src="ha-kanji-example.png" style="width:40.0%" /> <img data-src="ha-sketchrnn.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">SketchRNN Kanji (Ha, 2015); similar to handwriting generation, trained on kanji and then generates new ‚Äúfake‚Äù characters</li>
<li class="fragment">SketchRNN VAE (Ha et al., 2017); similar again, but trained on human-sourced sketches. VAE architecture with bidirectional RNN encoder and MDN in the decoder part.</li>
</ul>
</section>
<section id="use-cases-robojam" class="slide level2">
<h2>Use Cases: RoboJam</h2>
<div class="columns">
<div class="column">
<iframe src="https://giphy.com/embed/l1Lc4C4TcCTI4Wi8o" width="270" height="480" frameBorder="0" class="giphy-embed" allowFullScreen>
</iframe>
</div><div class="column">
<ul>
<li class="fragment">RoboJam (Martin et al., 2018); similar to the kanji RNN, but trained on touchscreen musical performances</li>
<li class="fragment">Extra complexity: have to model touch position (<span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>) and time (<span class="math inline">\(dt\)</span>).</li>
<li class="fragment">Implemented in my MicroJam app (have a go: <a href="https://microjam.info">microjam.info</a>)</li>
</ul>
</div>
</div>
</section>

<section class="slide level2">

<h3 id="use-cases-world-models">Use Cases: World Models</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment"><a href="https://worldmodels.github.io">World Models</a> (Ha &amp; Schmidhuber, 2018)</li>
<li class="fragment">Train a VAE for visual perception an environment (e.g., VizDoom), now each frame from the environment can be represented by a vector <span class="math inline">\(z\)</span></li>
<li class="fragment">Train MDN to predict next <span class="math inline">\(z\)</span>, use this to help train an agent to operate in the environment.</li>
</ul>
</div><div class="column">
<p><img data-src="./mdn-world-model-1.png" style="width:70.0%" /> <img data-src="./mdn-world-model-2.png" style="width:70.0%" /></p>
</div>
</div>
</section>

<section id="references" class="slide level2">
<h2>References</h2>
<ol type="1">
<li>Christopher M. Bishop. 1994. Mixture Density Networks. <a href="http://publications.aston.ac.uk/373/">Technical Report NCRG/94/004</a>. Neural Computing Research Group, Aston University.</li>
<li>Axel Brando. 2017. Mixture Density Networks (MDN) for distribution and uncertainty estimation. Master‚Äôs thesis. Universitat Polit√®cnica de Catalunya.</li>
<li>A. Graves. 2013. Generating Sequences With Recurrent Neural Networks. ArXiv e-prints (Aug.¬†2013). <a href="https://arxiv.org/abs/1308.0850">ArXiv:1308.0850</a></li>
<li>David Ha and Douglas Eck. 2017. A Neural Representation of Sketch Drawings. ArXiv e-prints (April 2017). <a href="https://arxiv.org/abs/1704.03477">ArXiv:1704.03477</a></li>
<li>Charles P. Martin and Jim Torresen. 2018. RoboJam: A Musical Mixture Density Network for Collaborative Touchscreen Interaction. In Evolutionary and Biologically Inspired Music, Sound, Art and Design: EvoMUSART ‚Äô18, A. Liapis et al.¬†(Ed.). Lecture Notes in Computer Science, Vol. 10783. Springer International Publishing. DOI:<a href="http://dx.doi.org/10.1007/9778-3-319-77583-8_11">10.1007/9778-3-319-77583-8_11</a></li>
<li>D. Ha and J. Schmidhuber. 2018. Recurrent World Models Facilitate Policy Evolution. ArXiv e-prints (Sept.¬†2018). <a href="https://arxiv.org/abs/1809.01999">ArXiv:1809.01999</a></li>
</ol>
</section>
