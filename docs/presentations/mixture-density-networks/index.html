<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Charles Martin">
  <title>Mixture Density Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../assets/reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../assets/reveal.js/css/theme/white.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '../../assets/reveal.js/css/print/pdf.css' : '../../assets/reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="../../assets/reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Mixture Density Networks</h1>
  <p class="author">Charles Martin</p>
</section>

<section class="slide level2">

<!-- theme: "white" -->
<h3 id="so-far-rnns-that-model-categorical-data">So far; RNNs that Model Categorical Data</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment">Remember that most RNNs (and most deep learning models) end with a softmax layer.</li>
<li class="fragment">This layer outputs a probability distribution for a set of categorical predictions.</li>
<li class="fragment">E.g.:
<ul>
<li class="fragment">image labels,</li>
<li class="fragment">letters, words,</li>
<li class="fragment">musical notes,</li>
<li class="fragment">robot commands,</li>
<li class="fragment">moves in chess.</li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./charRNN-arch.png" style="width:95.0%" /> <img data-src="./charRNN-training.png" style="width:80.0%" /></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="expressive-data-is-often-continuous">Expressive Data is Often Continuous</h3>
<div class="columns">
<div class="column">
<p><img data-src="./music-interface-1.jpg" style="width:60.0%" /> <img data-src="./music-interface-2.png" style="width:60.0%" /></p>
</div><div class="column">
<p><img data-src="./music-interface-3.jpg" style="width:60.0%" /> <iframe src="https://giphy.com/embed/1AjE1Ci6w3w6fv4D2z" width="80%" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="so-are-bio-signals">So are Bio-Signals</h3>
<div class="columns">
<div class="column">
<p><img data-src="./continuous-data-ecg.png" style="width:60.0%" /></p>
</div><div class="column">
<p><img data-src="./continuous-data-eeg.png" style="width:60.0%" /> <img data-src="./continuous-data-music.png" style="width:60.0%" /></p>
</div>
</div>
<p>Image Credit: Wikimedia</p>
</section>
<section class="slide level2">

<h3 id="categorical-vs.continuous-models">Categorical vs. Continuous Models</h3>
<div class="columns">
<div class="column">
<p><img data-src="./categorical_plot.png" /></p>
</div><div class="column">
<p><img data-src="./mixture_plot.png" /></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="normal-gaussian-distribution">Normal (Gaussian) Distribution</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment">“Standard” probability distribution</li>
<li class="fragment">Has two parameters:
<ul>
<li class="fragment">mean (<span class="math inline">\(\mu\)</span>) and</li>
<li class="fragment">standard deviation (<span class="math inline">\(\sigma\)</span>)</li>
</ul></li>
<li class="fragment">Probability Density Function:
<ul>
<li class="fragment"><span class="math display">\[\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2} } e^{ -\frac{(x-\mu)^2}{2\sigma^2} }\]</span></li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./normal_distribution_mu0_sd5.png" style="width:100.0%" /></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="problem-normal-distribution-might-not-fit-data">Problem: Normal distribution might not fit data</h3>
<div class="columns">
<div class="column">
<p>What if the data is complicated?</p>
<ul>
<li class="fragment">It’s easy to “fit” a normal model to any data.
<ul>
<li class="fragment">Just calculate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li class="fragment">But this might not fit the data well.</li>
</ul>
</div><div class="column">
<p><img data-src="./complex_distribution_hist_and_normal.png" style="width:100.0%" /></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="mixture-of-normals">Mixture of Normals</h3>
<div class="columns">
<div class="column">
<p>Three groups of parameters:</p>
<ul>
<li class="fragment">means (<span class="math inline">\(\boldsymbol\mu\)</span>): location of each component</li>
<li class="fragment">standard deviations (<span class="math inline">\(\boldsymbol\sigma\)</span>): width of each component</li>
<li class="fragment">Weight (<span class="math inline">\(\boldsymbol\pi\)</span>): height of each curve</li>
<li class="fragment">Probability Density Function:
<ul>
<li class="fragment"><span class="math display">\[p(x) = \sum_{i=1}^K \pi_i\mathcal{N}(x \mid \mu, \sigma^2)\]</span></li>
</ul></li>
</ul>
</div><div class="column">
<p><img data-src="./complex_mixture.png" style="width:100.0%" /></p>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="this-solves-our-problem">This solves our problem:</h3>
<div class="columns">
<div class="column">
<p>Returning to our modelling problem, let’s plot the PDF of a evenly-weighted mixture of the two sample normal models.</p>
<p>We set:</p>
<ul>
<li class="fragment"><span class="math inline">\(K = 2\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\pi = [0.5, 0.5]\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\mu = [-5, 5]\)</span></li>
<li class="fragment"><span class="math inline">\(\boldsymbol\sigma = [2, 3]\)</span></li>
<li class="fragment">(bold used to indicate the vector of parameters for each component)</li>
</ul>
<p>In this case, I knew the right parameters, but normally you would have to <em>estimate</em>, or <em>learn</em>, these somehow…</p>
</div><div class="column">
<p><img data-src="./complex_distribution_hist_and_mixture.png" style="width:100.0%" /></p>
</div>
</div>
</section>
<section id="mixture-density-networks" class="slide level2">
<h2>Mixture Density Networks</h2>
<p><img data-src="./mse-network-normal.png" /></p>
<ul>
<li class="fragment">Neural networks used to model complicated real-valued data.
<ul>
<li class="fragment">i.e., data that might not be very “normal”</li>
</ul></li>
<li class="fragment">Usual approach: use a neuron with linear activation to make predictions.
<ul>
<li class="fragment">Training function could be MSE (mean squared error).</li>
</ul></li>
<li class="fragment">Problem! This is equivalent to fitting to a single normal model! 😱</li>
<li class="fragment">(See Bishop, C (1994) for proof and more details)</li>
</ul>
</section>
<section id="mixture-density-networks-1" class="slide level2">
<h2>Mixture Density Networks</h2>
<p><img data-src="./mdn-network.png" /></p>
<ul>
<li class="fragment">Idea: output parameters of a mixture model instead!</li>
<li class="fragment">Rather than MSE for training, use the PDF of the mixture model.</li>
<li class="fragment">Now network can model complicated distributions! 😌</li>
</ul>
</section>
<section id="simple-example-in-keras" class="slide level2">
<h2>Simple Example in Keras</h2>
<p><img data-src="./arcsine-function.png" style="width:30.0%" /></p>
<ul>
<li class="fragment">Difficult data is not hard to find! Think about modelling an inverse sine (arcsine) function.
<ul>
<li class="fragment">Each input value takes multiple outputs…</li>
<li class="fragment">This is not going to go well for a single normal model.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="feedforward-mse-network">Feedforward MSE Network</h3>
<p><img data-src="./arcsine-feedforward-mse-prediction.png" style="width:30.0%" /> <img data-src="./feedforward-mse-prediction-loss-plot.png" style="width:40.0%" /></p>
<p>Here’s a simple two-hidden-layer network (286 parameters), trained to produce the above result.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1">model <span class="op">=</span> Sequential()</a>
<a class="sourceLine" id="cb1-2" title="2">model.add(Dense(<span class="dv">15</span>, batch_input_shape<span class="op">=</span>(<span class="va">None</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>))</a>
<a class="sourceLine" id="cb1-3" title="3">model.add(Dense(<span class="dv">15</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>))</a>
<a class="sourceLine" id="cb1-4" title="4">model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;linear&#39;</span>))</a>
<a class="sourceLine" id="cb1-5" title="5">model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;mse&#39;</span>, optimizer<span class="op">=</span><span class="st">&#39;rmsprop&#39;</span>)</a>
<a class="sourceLine" id="cb1-6" title="6">model.fit(x<span class="op">=</span>x_data, y<span class="op">=</span>y_data, batch_size<span class="op">=</span><span class="dv">128</span>, epochs<span class="op">=</span><span class="dv">200</span>, validation_split<span class="op">=</span><span class="fl">0.15</span>)</a></code></pre></div>
</section>
<section id="mdn-architecture" class="slide level2">
<h2>MDN Architecture:</h2>
<p><img data-src="./mdn-network.png" /></p>
<ul>
<li class="fragment">Loss function for MDN is negative log of likelihood function <span class="math inline">\(\mathcal{L}\)</span>.</li>
<li class="fragment"><span class="math inline">\(\mathcal{L}\)</span> measures likelihood of <span class="math inline">\(t\)</span> being drawn from a mixture parametrised by <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(\pi\)</span> which are generated by the network inputs <span class="math inline">\(x\)</span>:</li>
</ul>
<p><span class="math display">\[\mathcal{L} = \sum_{i=1}^K\pi_i(\mathbf{x})\mathcal{N}\bigl(\mu_i(\mathbf{x}), \sigma_i^2(\mathbf{x}); \mathbf{t} \bigr)\]</span></p>
</section>
<section class="slide level2">

<h3 id="feedforward-mdn-solution">Feedforward MDN Solution</h3>
<p><img data-src="./arcsine-feedforward-mdn-predictions.png" style="width:30.0%" /> <img data-src="./arcsine-feedforward-mdn-loss.png" style="width:40.0%" /></p>
<p>And, here’s a simple two-hidden-layer MDN (510 parameters), that achieves the above result! Much better!</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">N_MIXES <span class="op">=</span> <span class="dv">5</span></a>
<a class="sourceLine" id="cb2-2" title="2"></a>
<a class="sourceLine" id="cb2-3" title="3">model <span class="op">=</span> Sequential()</a>
<a class="sourceLine" id="cb2-4" title="4">model.add(Dense(<span class="dv">15</span>, batch_input_shape<span class="op">=</span>(<span class="va">None</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</a>
<a class="sourceLine" id="cb2-5" title="5">model.add(Dense(<span class="dv">15</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</a>
<a class="sourceLine" id="cb2-6" title="6">model.add(mdn.MDN(<span class="dv">1</span>, N_MIXES)) <span class="co"># here&#39;s the MDN layer!</span></a>
<a class="sourceLine" id="cb2-7" title="7">model.<span class="bu">compile</span>(loss<span class="op">=</span>mdn.get_mixture_loss_func(<span class="dv">1</span>,N_MIXES), optimizer<span class="op">=</span><span class="st">&#39;rmsprop&#39;</span>)</a>
<a class="sourceLine" id="cb2-8" title="8">model.summary()</a></code></pre></div>
</section>
<section class="slide level2">

<h3 id="getting-inside-the-mdn-layer">Getting inside the MDN layer</h3>
<p>Here’s the same network wihtout using the MDN layer abstraction (this is with Keras’ functional API):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">def</span> elu_plus_one_plus_epsilon(x):</a>
<a class="sourceLine" id="cb3-2" title="2">    <span class="co">&quot;&quot;&quot;ELU activation with a very small addition to help prevent NaN in loss.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb3-3" title="3">    <span class="cf">return</span> (K.elu(x) <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="fl">1e-8</span>)</a>
<a class="sourceLine" id="cb3-4" title="4"></a>
<a class="sourceLine" id="cb3-5" title="5">N_HIDDEN <span class="op">=</span> <span class="dv">15</span></a>
<a class="sourceLine" id="cb3-6" title="6">N_MIXES <span class="op">=</span> <span class="dv">5</span></a>
<a class="sourceLine" id="cb3-7" title="7"></a>
<a class="sourceLine" id="cb3-8" title="8">inputs <span class="op">=</span> Input(shape<span class="op">=</span>(<span class="dv">1</span>,), name<span class="op">=</span><span class="st">&#39;inputs&#39;</span>)</a>
<a class="sourceLine" id="cb3-9" title="9">hidden1 <span class="op">=</span> Dense(N_HIDDEN, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&#39;hidden1&#39;</span>)(inputs)</a>
<a class="sourceLine" id="cb3-10" title="10">hidden2 <span class="op">=</span> Dense(N_HIDDEN, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, name<span class="op">=</span><span class="st">&#39;hidden2&#39;</span>)(hidden1)</a>
<a class="sourceLine" id="cb3-11" title="11"></a>
<a class="sourceLine" id="cb3-12" title="12">mdn_mus <span class="op">=</span> Dense(N_MIXES, name<span class="op">=</span><span class="st">&#39;mdn_mus&#39;</span>)(hidden2)</a>
<a class="sourceLine" id="cb3-13" title="13">mdn_sigmas <span class="op">=</span> Dense(N_MIXES, activation<span class="op">=</span>elu_plus_one_plus_epsilon, name<span class="op">=</span><span class="st">&#39;mdn_sigmas&#39;</span>)(hidden2)</a>
<a class="sourceLine" id="cb3-14" title="14">mdn_pi <span class="op">=</span> Dense(N_MIXES, name<span class="op">=</span><span class="st">&#39;mdn_pi&#39;</span>)(hidden2)</a>
<a class="sourceLine" id="cb3-15" title="15"></a>
<a class="sourceLine" id="cb3-16" title="16">mdn_out <span class="op">=</span> Concatenate(name<span class="op">=</span><span class="st">&#39;mdn_outputs&#39;</span>)([mdn_mus, mdn_sigmas, mdn_pi])</a>
<a class="sourceLine" id="cb3-17" title="17"></a>
<a class="sourceLine" id="cb3-18" title="18">model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>mdn_out)</a>
<a class="sourceLine" id="cb3-19" title="19">model.summary()</a></code></pre></div>
</section>
<section id="loss-function-the-tricky-bit." class="slide level2">
<h2>Loss Function: The Tricky Bit.</h2>
<p>Loss function for the MDN should be the negative log likelihood:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">def</span> mdn_loss(y_true, y_pred):</a>
<a class="sourceLine" id="cb4-2" title="2">    <span class="co"># Split the inputs into paramaters</span></a>
<a class="sourceLine" id="cb4-3" title="3">    out_mu, out_sigma, out_pi <span class="op">=</span> tf.split(y_pred, num_or_size_splits<span class="op">=</span>[N_MIXES, N_MIXES, N_MIXES],</a>
<a class="sourceLine" id="cb4-4" title="4">                                         axis<span class="op">=-</span><span class="dv">1</span>, name<span class="op">=</span><span class="st">&#39;mdn_coef_split&#39;</span>)</a>
<a class="sourceLine" id="cb4-5" title="5">    mus <span class="op">=</span> tf.split(out_mu, num_or_size_splits<span class="op">=</span>N_MIXES, axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-6" title="6">    sigs <span class="op">=</span> tf.split(out_sigma, num_or_size_splits<span class="op">=</span>N_MIXES, axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-7" title="7">    <span class="co"># Construct the mixture models</span></a>
<a class="sourceLine" id="cb4-8" title="8">    cat <span class="op">=</span> tfd.Categorical(logits<span class="op">=</span>out_pi)</a>
<a class="sourceLine" id="cb4-9" title="9">    coll <span class="op">=</span> [tfd.MultivariateNormalDiag(loc<span class="op">=</span>loc, scale_diag<span class="op">=</span>scale) <span class="cf">for</span> loc, scale</a>
<a class="sourceLine" id="cb4-10" title="10">            <span class="kw">in</span> <span class="bu">zip</span>(mus, sigs)]</a>
<a class="sourceLine" id="cb4-11" title="11">    mixture <span class="op">=</span> tfd.Mixture(cat<span class="op">=</span>cat, components<span class="op">=</span>coll)</a>
<a class="sourceLine" id="cb4-12" title="12">    <span class="co"># Calculate the loss function</span></a>
<a class="sourceLine" id="cb4-13" title="13">    loss <span class="op">=</span> mixture.log_prob(y_true)</a>
<a class="sourceLine" id="cb4-14" title="14">    loss <span class="op">=</span> tf.negative(loss)</a>
<a class="sourceLine" id="cb4-15" title="15">    loss <span class="op">=</span> tf.reduce_mean(loss)</a>
<a class="sourceLine" id="cb4-16" title="16">    <span class="cf">return</span> loss</a>
<a class="sourceLine" id="cb4-17" title="17"></a>
<a class="sourceLine" id="cb4-18" title="18">model.<span class="bu">compile</span>(loss<span class="op">=</span>mdn_loss, optimizer<span class="op">=</span><span class="st">&#39;rmsprop&#39;</span>)</a></code></pre></div>
<p>Let’s go through bit by bit…</p>
</section>
<section id="loss-function-part-1" class="slide level2">
<h2>Loss Function: Part 1:</h2>
<p>First we have to extract the mixture paramaters.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1"><span class="co"># Split the inputs into paramaters</span></a>
<a class="sourceLine" id="cb5-2" title="2">out_mu, out_sigma, out_pi <span class="op">=</span> tf.split(y_pred, num_or_size_splits<span class="op">=</span>[N_MIXES, N_MIXES, N_MIXES],</a>
<a class="sourceLine" id="cb5-3" title="3">                                     axis<span class="op">=-</span><span class="dv">1</span>, name<span class="op">=</span><span class="st">&#39;mdn_coef_split&#39;</span>)</a>
<a class="sourceLine" id="cb5-4" title="4">mus <span class="op">=</span> tf.split(out_mu, num_or_size_splits<span class="op">=</span>N_MIXES, axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb5-5" title="5">sigs <span class="op">=</span> tf.split(out_sigma, num_or_size_splits<span class="op">=</span>N_MIXES, axis<span class="op">=</span><span class="dv">1</span>)</a></code></pre></div>
<ul>
<li class="fragment">Split up the parameters <span class="math inline">\(\boldsymbol\mu\)</span>, <span class="math inline">\(\boldsymbol\sigma\)</span>, and <span class="math inline">\(\boldsymbol\pi\)</span>, remember that there are N_MIXES <span class="math inline">\(= K\)</span> of each of these.</li>
<li class="fragment"><span class="math inline">\(\boldsymbol\mu\)</span> and <span class="math inline">\(\boldsymbol\sigma\)</span> have to be split <em>again</em> so that we can iterate over them (you can’t iterate over an axis of a tensor…)</li>
</ul>
</section>
<section id="loss-function-part-2" class="slide level2">
<h2>Loss Function: Part 2:</h2>
<p>Now we have to construct the mixture model’s PDF.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># Construct the mixture models</span></a>
<a class="sourceLine" id="cb6-2" title="2">cat <span class="op">=</span> tfd.Categorical(logits<span class="op">=</span>out_pi) </a>
<a class="sourceLine" id="cb6-3" title="3">coll <span class="op">=</span> [tfd.Normal(loc<span class="op">=</span>loc, scale<span class="op">=</span>scale) <span class="cf">for</span> loc, scale</a>
<a class="sourceLine" id="cb6-4" title="4">        <span class="kw">in</span> <span class="bu">zip</span>(mus, sigs)]</a>
<a class="sourceLine" id="cb6-5" title="5">mixture <span class="op">=</span> tfd.Mixture(cat<span class="op">=</span>cat, components<span class="op">=</span>coll)</a></code></pre></div>
<ul>
<li class="fragment">For this, we’re using the <code>Mixture</code> abstraction provided in <code>tensorflow-probability.distributions</code>.</li>
<li class="fragment">This takes a categorical (a.k.a. softmax, a.k.a. generalized Bernoulli distribution) model, and a list the component distributions.</li>
<li class="fragment">Each normal PDF is contructed using <code>tfd.Normal</code>.</li>
<li class="fragment">Can do this from first principles as well, but good to use abstractions that are available (?)</li>
</ul>
</section>
<section id="loss-function-part-3" class="slide level2">
<h2>Loss Function: Part 3:</h2>
<p>Finally, we calculate the loss:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python numberLines"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" title="1">loss <span class="op">=</span> mixture.log_prob(y_true)</a>
<a class="sourceLine" id="cb7-2" title="2">loss <span class="op">=</span> tf.negative(loss)</a>
<a class="sourceLine" id="cb7-3" title="3">loss <span class="op">=</span> tf.reduce_mean(loss)</a></code></pre></div>
<ul>
<li class="fragment"><code>mixture.log_prob(y_true)</code> means “the log-likelihood of sampling <code>y_true</code> from the distribution called <code>mixture</code>.”</li>
</ul>
</section>
<section id="some-more-details." class="slide level2">
<h2>Some more details….</h2>
<p><img data-src="./MultivariateNormal.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">This “version” of a mixture model works for a mixture of 1D normal distributions.</li>
<li class="fragment">Not too hard to extend to multivariate normal distributions, which are useful for lots of problems.</li>
<li class="fragment">This is how it actually works in my Keras MDN layer, <a href="https://github.com/cpmpercussion/keras-mdn-layer/">have a look at the code for more details…</a></li>
</ul>
</section>
<section id="mdn-rnns" class="slide level2">
<h2>MDN-RNNs</h2>
<p><img data-src="mdn-rnn-movement-example.png" /></p>
<p>MDNs can be handy at the end of an RNN! Imagine a robot calculating moves forward through space, it might have to choose from a number of valid positions, each of which could be modelled by a 2D Normal model.</p>
</section>
<section id="mdn-rnn-architecture" class="slide level2">
<h2>MDN-RNN Architecture</h2>
<p><img data-src="mdn-rnn-architecture-simple.png" /></p>
<p>Can be as simple as putting an MDN layer after recurrent layers!</p>
</section>
<section id="use-cases-handwriting-generation" class="slide level2">
<h2>Use Cases: Handwriting Generation</h2>
<p><img data-src="graves-handwriting-generation.png" style="width:40.0%" /> <img data-src="graves-handwriting2.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">Handwriting Generation RNN (Graves, 2013).</li>
<li class="fragment">Trained on handwriting data.</li>
<li class="fragment">Predicts the next location of the pen (<span class="math inline">\(dx\)</span>, <span class="math inline">\(dy\)</span>, and up/down)</li>
<li class="fragment">Network takes text to write as an extra input, RNN learns to decide what character to write next.</li>
</ul>
</section>
<section id="use-cases-sketchrnn" class="slide level2">
<h2>Use Cases: SketchRNN</h2>
<p><img data-src="ha-kanji-example.png" style="width:40.0%" /> <img data-src="ha-sketchrnn.png" style="width:40.0%" /></p>
<ul>
<li class="fragment">SketchRNN Kanji (Ha, 2015); similar to handwriting generation, trained on kanji and then generates new “fake” characters</li>
<li class="fragment">SketchRNN VAE (Ha et al., 2017); similar again, but trained on human-sourced sketches. VAE architecture with bidirectional RNN encoder and MDN in the decoder part.</li>
</ul>
</section>
<section id="use-cases-robojam" class="slide level2">
<h2>Use Cases: RoboJam</h2>
<div class="columns">
<div class="column">
<iframe src="https://giphy.com/embed/l1Lc4C4TcCTI4Wi8o" width="270" height="480" frameBorder="0" class="giphy-embed" allowFullScreen>
</iframe>
</div><div class="column">
<ul>
<li class="fragment">RoboJam (Martin et al., 2018); similar to the kanji RNN, but trained on touchscreen musical performances</li>
<li class="fragment">Extra complexity: have to model touch position (<span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>) and time (<span class="math inline">\(dt\)</span>).</li>
<li class="fragment">Implemented in my MicroJam app (have a go: <a href="https://microjam.info">microjam.info</a>)</li>
</ul>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="use-cases-world-models">Use Cases: World Models</h3>
<div class="columns">
<div class="column">
<ul>
<li class="fragment"><a href="https://worldmodels.github.io">World Models</a> (Ha &amp; Schmidhuber, 2018)</li>
<li class="fragment">Train a VAE for visual perception an environment (e.g., VizDoom), now each frame from the environment can be represented by a vector <span class="math inline">\(z\)</span></li>
<li class="fragment">Train MDN to predict next <span class="math inline">\(z\)</span>, use this to help train an agent to operate in the environment.</li>
</ul>
</div><div class="column">
<p><img data-src="./mdn-world-model-1.png" style="width:80.0%" /> <img data-src="./mdn-world-model-2.png" style="width:80.0%" /></p>
</div>
</div>
</section>
<section id="references" class="slide level2">
<h2>References</h2>
<ol type="1">
<li class="fragment">Christopher M. Bishop. 1994. Mixture Density Networks. <a href="http://publications.aston.ac.uk/373/">Technical Report NCRG/94/004</a>. Neural Computing Research Group, Aston University.</li>
<li class="fragment">Axel Brando. 2017. Mixture Density Networks (MDN) for distribution and uncertainty estimation. Master’s thesis. Universitat Politècnica de Catalunya.</li>
<li class="fragment">A. Graves. 2013. Generating Sequences With Recurrent Neural Networks. ArXiv e-prints (Aug. 2013). <a href="https://arxiv.org/abs/1308.0850">ArXiv:1308.0850</a></li>
<li class="fragment">David Ha and Douglas Eck. 2017. A Neural Representation of Sketch Drawings. ArXiv e-prints (April 2017). <a href="https://arxiv.org/abs/1704.03477">ArXiv:1704.03477</a></li>
<li class="fragment">Charles P. Martin and Jim Torresen. 2018. RoboJam: A Musical Mixture Density Network for Collaborative Touchscreen Interaction. In Evolutionary and Biologically Inspired Music, Sound, Art and Design: EvoMUSART ’18, A. Liapis et al. (Ed.). Lecture Notes in Computer Science, Vol. 10783. Springer International Publishing. DOI:<a href="http://dx.doi.org/10.1007/9778-3-319-77583-8_11">10.1007/9778-3-319-77583-8_11</a></li>
<li class="fragment">D. Ha and J. Schmidhuber. 2018. Recurrent World Models Facilitate Policy Evolution. ArXiv e-prints (Sept. 2018). <a href="https://arxiv.org/abs/1809.01999">ArXiv:1809.01999</a></li>
</ol>
</section>
    </div>
  </div>

  <script src="../../assets/reveal.js/lib/js/head.min.js"></script>
  <script src="../../assets/reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: '../../assets/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../../assets/reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: '../../assets/reveal.js/plugin/math/math.js', async: true },
          { src: '../../assets/reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
