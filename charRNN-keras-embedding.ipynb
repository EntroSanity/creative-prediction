{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trained on 1MB of Shakespeare.\n",
    "- Outputs \"fake\" Shakespeare.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Shakespeare corpus\n",
    "- Give each leter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1115394\n",
      "total chars: 39\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(\"tiny-shakespeare.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into sequences of 40 characters.\n",
    "- Change indexes into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 371782\n",
      "Done converting y to one-hot.\n",
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (371782, 50)\n",
      "y shape: (371782, 39)\n",
      "Vocabulary of characters: 39\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 50\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "X = np.zeros((len(sentences), maxlen), dtype=int)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    X[i] = np.array(map((lambda x: char_indices[x]), sentences[i]))\n",
    "    y[i, char_indices[next_chars[i]]] = True\n",
    "print(\"Done converting y to one-hot.\")\n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Input layer is an Embedding to convert from indices to a vector encoding automatically (common trick - but does it work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 128)           4992      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 39)                5031      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 39)                0         \n",
      "=================================================================\n",
      "Total params: 141,607.0\n",
      "Trainable params: 141,607.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, 128, input_length=maxlen))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocabulary_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model.summary()\n",
    "\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "371782/371782 [==============================] - 988s - loss: 1.8316   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110923050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model.\n",
    "model.fit(X, y, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras-shakespeare-LSTM-model-emb.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  be not afraid of greatness: some are born great, s\n",
      "Generated:  be not afraid of greatness: some are born great, since i have be prepence an it master heaven\n",
      "the record own therefore the down an an heart\n",
      "that thee with the dame hearts you to will it the percomes would boldness heart on her have my tower her.\n",
      "\n",
      "secong shall the capetis:\n",
      "what he may man;\n",
      "and the stand an earth,\n",
      "and i the bantent of the man to how the mannte that a prepenting of how he the dead heart i dienter the prepain of deade and men to be have my grace of the head of my beace of him in heaving head's the heaven and the mack the slempence\n",
      "the will the live them.\n",
      "\n",
      "shecinius:\n",
      "when the from the montague that i that the made.\n",
      "\n",
      "petruchio:\n",
      "and in deady.\n",
      "\n",
      "petruchio:\n",
      "i with the man must it is the sent the world him diend the drispite well the head the with the shall is heart:\n",
      "im would the death the warwick.\n",
      "\n",
      "petruchio:\n",
      "and it there to with her have my richard an on the come, done thou did a traity heaving in heart the man with the shall the caperce\n",
      "of my dich with the diend did well.\n",
      "\n",
      "lady brother:\n",
      "my bold of head her go himpt an it not \n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"keras-shakespeare-LSTM-model-emb.h5\")\n",
    "quote = \"Be not afraid of greatness: some are born great, some achieve greatness, and some have greatness thrust upon them.\"\n",
    "quote = quote.lower()\n",
    "\n",
    "def sample_model(seed, length=400):\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:50]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array(map((lambda x: char_indices[x]), sentence))\n",
    "        x = np.reshape(x,(1,50))\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)\n",
    "\n",
    "sample_model(quote, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
