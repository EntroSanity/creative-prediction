{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- Give each leter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11010\n",
      "total chars: 49\n",
      "Max: 50\n",
      "Mean: 14.0013623978\n",
      "Median: 13.0\n",
      "Min: 2\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into sequences of 40 characters.\n",
    "- Change indexes into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3660\n",
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3660, 30)\n",
      "y shape: (3660, 49)\n",
      "Vocabulary of characters: 49\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "seq_len = 30\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sentences.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "X = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    X[i] = np.array([char_indices[x] for x in sentences[i]])\n",
    "    y[i, char_indices[next_chars[i]]] = True\n",
    "\n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Input layer is an Embedding to convert from indices to a vector encoding automatically (common trick - but does it work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 128)           6272      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 49)                6321      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 49)                0         \n",
      "=================================================================\n",
      "Total params: 275,761\n",
      "Trainable params: 275,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_size = 128\n",
    "dropout_rate = 0.5\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model_train = Sequential()\n",
    "model_train.add(Embedding(vocabulary_size, layer_size, input_length=maxlen))\n",
    "\n",
    "# LSTM part\n",
    "model_train.add(LSTM(layer_size, return_sequences=True))\n",
    "model_train.add(LSTM(layer_size))\n",
    "\n",
    "# Project back to vocabulary\n",
    "model_train.add(Dense(vocabulary_size))\n",
    "model_train.add(Activation('softmax'))\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3660/3660 [==============================] - 6s 2ms/step - loss: 3.2456\n",
      "Epoch 2/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.9933\n",
      "Epoch 3/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.7041\n",
      "Epoch 4/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.4996\n",
      "Epoch 5/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.3949\n",
      "Epoch 6/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.2981\n",
      "Epoch 7/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.2025\n",
      "Epoch 8/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.0798\n",
      "Epoch 9/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 1.9792\n",
      "Epoch 10/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 1.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113433828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model.\n",
    "model_train.fit(X, y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1235bee10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121daa160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(model_train.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters.\n",
    "\n",
    "### Make a Decoder model\n",
    "\n",
    "- Needs input length of 1.\n",
    "- Needs batch size of 1\n",
    "- Needs LSTM to be stateful\n",
    "- check that params is the same as model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if necessary.\n",
    "model_train = load_model(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, 1, 128)               6272      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (1, 1, 128)               131584    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (1, 128)                  131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, 49)                   6321      \n",
      "=================================================================\n",
      "Total params: 275,761\n",
      "Trainable params: 275,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a decoding model (input length 1, batch size 1, stateful)\n",
    "\n",
    "model_dec = Sequential()\n",
    "model_dec.add(Embedding(vocabulary_size, layer_size, input_length=1, batch_input_shape=(1,1)))\n",
    "\n",
    "# LSTM part\n",
    "model_dec.add(LSTM(layer_size, stateful=True, return_sequences=True))\n",
    "model_dec.add(LSTM(layer_size, stateful=True))\n",
    "\n",
    "# project back to vocabulary\n",
    "model_dec.add(Dense(vocabulary_size, activation='softmax'))\n",
    "model_dec.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_dec.summary()\n",
    "\n",
    "# set weights from training model\n",
    "model_dec.set_weights(model_train.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling function\n",
    "\n",
    "def sample_model(seed, model_name, length=400):\n",
    "    '''Samples a charRNN given a seed sequence.'''\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array([char_indices[n] for n in sentence])\n",
    "        x = np.reshape(x,(1,1))\n",
    "        preds = model_name.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  (\n",
      "Generated:  (aieter\n",
      "the paardor\n",
      "the parsimer port onime parssion\n",
      "the weardimen of murg\n",
      "of the pird soird sumil\n",
      "the pars\n",
      "the part 1)\n",
      "invigion\n",
      "the wirds part 1)\n",
      "part 1)\n",
      "part 1.1\n",
      "part 1)\n",
      "parkace\n",
      "simplice\n",
      "star\n",
      "the part i)\n",
      "parspirk\n",
      "the paar par\n",
      "corsond\n",
      "miger\n",
      "the part 1)\n",
      "incinater\n",
      "mird vorim meris\n",
      "the part 1)\n",
      "part 11)\n",
      "homil\n",
      "the dight\n",
      "armone to parssion\n",
      "mighs\n",
      "the pars\n",
      "the morder\n",
      "the purday\n",
      "parspar\n",
      "the percore\n",
      "the parsier\n",
      "morm\n",
      "the pars\n",
      "ay\n",
      "the parsior\n",
      "pright\n",
      "amith\n",
      "the parsirin deard\n",
      "risgad\n",
      "the parsir merorpay\n",
      "the pissing\n",
      "the pars\n",
      "and lear\n",
      "the part 1)\n",
      "ard ument\n",
      "darker the part 1)\n",
      "the pargime\n",
      "the part 1part 1)\n",
      "emenciry\n",
      "the moncing\n",
      "of pirki\n",
      "the parsilring\n",
      "the parsity\n",
      "moring\n",
      "burd parsint\n",
      "the pars osd\n",
      "ampurel\n",
      "the park part i\n",
      "part 1): part one\n",
      "part i)\n",
      "imber\n",
      "the part 1)\n",
      "part 1)\n",
      "scepeer\n",
      "the peation\n",
      "the pard pars of wingnur\n",
      "the parsil mor\n",
      "mirr\n",
      "the pards part part 1)\n",
      "dird surdindor\n",
      "the pars\n",
      "the virginc\n",
      "the part 1briger\n",
      "scirn\n",
      "wont unqing\n",
      "the pars, part 1)\n",
      "part i)\n",
      "the part 1)\n",
      "parsilit part 1)\n",
      "prorter\n",
      "the parser\n",
      "homing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 1000 characters from the model using a random seed from the vocabulary.\n",
    "sample_model(indices_char[random.randint(0,vocabulary_size-1)], model_dec, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments - Model Maker\n",
    "\n",
    "A single function to make both training and running models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(model, layer_size=64, dropout_rate=0.5, num_layers=1, vocab_size=20, input_length=1, lr=0.01, train_mode=True):\n",
    "    \"\"\"Builds a charRNN model with variable layer size, number of layers, droupout, learning rate, and a training mode.\"\"\"\n",
    "    if train_mode:\n",
    "        stateful = False\n",
    "        input_shape = (None, input_length)\n",
    "    else:\n",
    "        stateful = True\n",
    "        input_shape = (1, input_length)\n",
    "    \n",
    "    # Input embedding\n",
    "    model.add(Embedding(vocab_size, layer_size, input_length=input_length, batch_input_shape=input_shape))\n",
    "              \n",
    "    # LSTM layers + 1\n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(LSTM(layer_size, return_sequences=True, stateful=stateful))\n",
    "    \n",
    "    # Final LSTM layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(layer_size, stateful=stateful))\n",
    "\n",
    "    # Project back to vocabulary\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=lr))\n",
    "    model.summary()\n",
    "\n",
    "# m = Sequential()\n",
    "# model_maker(m, layer_size=128, vocab_size=vocabulary_size, input_length=30, train_mode=True)\n",
    "# m.fit(X, y, batch_size=64, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
