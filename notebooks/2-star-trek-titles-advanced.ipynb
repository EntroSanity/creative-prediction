{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- Give each leter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11010\n",
      "total chars: 49\n",
      "Max: 50\n",
      "Mean: 14.0013623978\n",
      "Median: 13.0\n",
      "Min: 2\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open(\"../startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into sequences of 40 characters.\n",
    "- Change indexes into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3660\n",
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3660, 30)\n",
      "y shape: (3660,)\n",
      "Vocabulary of characters: 49\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "seq_len = 30\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sentences.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "X = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "y = np.zeros(len(sentences), dtype=int)\n",
    "# y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    X[i] = np.array([char_indices[x] for x in sentences[i]])\n",
    "    y[i] = char_indices[next_chars[i]]\n",
    "    #y[i, char_indices[next_chars[i]]] = True\n",
    "\n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Input layer is an Embedding to convert from indices to a vector encoding automatically (common trick - but does it work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 128)           6272      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 49)                6321      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 49)                0         \n",
      "=================================================================\n",
      "Total params: 275,761\n",
      "Trainable params: 275,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_size = 128\n",
    "dropout_rate = 0.5\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model_train = Sequential()\n",
    "model_train.add(Embedding(vocabulary_size, layer_size, input_length=seq_len))\n",
    "\n",
    "# LSTM part\n",
    "model_train.add(LSTM(layer_size, return_sequences=True))\n",
    "model_train.add(LSTM(layer_size))\n",
    "\n",
    "# Project back to vocabulary\n",
    "model_train.add(Dense(vocabulary_size))\n",
    "model_train.add(Activation('softmax'))\n",
    "model_train.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "model_train.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3660/3660 [==============================] - 5s 1ms/step - loss: 3.1697\n",
      "Epoch 2/10\n",
      "3660/3660 [==============================] - 4s 983us/step - loss: 3.0875\n",
      "Epoch 3/10\n",
      "3660/3660 [==============================] - 4s 992us/step - loss: 3.0158\n",
      "Epoch 4/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.8103\n",
      "Epoch 5/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.6651\n",
      "Epoch 6/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.5781\n",
      "Epoch 7/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.5173\n",
      "Epoch 8/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.4586\n",
      "Epoch 9/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.4071\n",
      "Epoch 10/10\n",
      "3660/3660 [==============================] - 4s 1ms/step - loss: 2.3591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120e00f60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model.\n",
    "model_train.fit(X, y, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122051780>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124110b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(model_train.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters.\n",
    "\n",
    "### Make a Decoder model\n",
    "\n",
    "- Needs input length of 1.\n",
    "- Needs batch size of 1\n",
    "- Needs LSTM to be stateful\n",
    "- check that params is the same as model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if necessary.\n",
    "model_train = load_model(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, 1, 128)               6272      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (1, 1, 128)               131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (1, 128)                  131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 49)                   6321      \n",
      "=================================================================\n",
      "Total params: 275,761\n",
      "Trainable params: 275,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a decoding model (input length 1, batch size 1, stateful)\n",
    "\n",
    "model_dec = Sequential()\n",
    "model_dec.add(Embedding(vocabulary_size, layer_size, input_length=1, batch_input_shape=(1,1)))\n",
    "\n",
    "# LSTM part\n",
    "model_dec.add(LSTM(layer_size, stateful=True, return_sequences=True))\n",
    "model_dec.add(LSTM(layer_size, stateful=True))\n",
    "\n",
    "# project back to vocabulary\n",
    "model_dec.add(Dense(vocabulary_size, activation='softmax'))\n",
    "model_dec.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_dec.summary()\n",
    "\n",
    "# set weights from training model\n",
    "model_dec.set_weights(model_train.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling function\n",
    "\n",
    "def sample_model(seed, model_name, length=400):\n",
    "    '''Samples a charRNN given a seed sequence.'''\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array([char_indices[n] for n in sentence])\n",
    "        x = np.reshape(x,(1,1))\n",
    "        preds = model_name.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  r\n",
      "Generated:  rnon\n",
      "ond the same\n",
      "mond sil san\n",
      "fere\n",
      "the cert re\n",
      "the wese\n",
      "the bete ant in\n",
      "the incone\n",
      "the memet on\n",
      "the the the the malation s\n",
      "phint on\n",
      "the the on fent an\n",
      "the the dore\n",
      "the ons\n",
      "seten\n",
      "the bolt of in\n",
      "methe mane\n",
      "sod anm\n",
      "mespont\n",
      "the cont con\n",
      "the pone ther\n",
      "the lendi\n",
      "an ontin\n",
      "the ceron\n",
      "the wat on\n",
      "the ant mare\n",
      "fis af ot on\n",
      "the ons to fore\n",
      "the soge\n",
      "bonde\n",
      "catte\n",
      "the onme\n",
      "the the rerois tr\n",
      "the post on\n",
      "the pos anes\n",
      "sos o the seridil\n",
      "sine\n",
      "the merit on\n",
      "the patar\n",
      "the the poncon\n",
      "the the perat on\n",
      "the efety\n",
      "the simet in\n",
      "the fare\n",
      "the lolat on\n",
      "the the les ol\n",
      "shose mon te\n",
      "the penty\n",
      "me the reme tor\n",
      "the ane\n",
      "emend\n",
      "the moas\n",
      "tome\n",
      "satte\n",
      "ontin sonhe\n",
      "the se lourg\n",
      "vert\n",
      "the ante\n",
      "sheress\n",
      "the ithe\n",
      "seime\n",
      "the ine\n",
      "the tont on\n",
      "te piut an\n",
      "ont int on\n",
      "the ense\n",
      "the mereti\n",
      "the deout in\n",
      "shon\n",
      "the emesc\n",
      "the afedim\n",
      "the pat on\n",
      "the bof if (ne\n",
      "the mothe\n",
      "serent ar\n",
      "the af tar\n",
      "the beut on l\n",
      "the on ot on ome tars\n",
      "tare\n",
      "the wet at on\n",
      "the of mort tiot on\n",
      "the on on the weme\n",
      "the on the pere\n",
      "the ser\n",
      "the the mare son\n",
      "the conte\n",
      "sate\n",
      "the ene the cir\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# Sample 1000 characters from the model using a random seed from the vocabulary.\n",
    "sample_model(indices_char[random.randint(0,vocabulary_size-1)], model_dec, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments - Model Maker\n",
    "\n",
    "A single function to make both training and running models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(model, layer_size=64, dropout_rate=0.5, num_layers=1, vocab_size=20, input_length=1, lr=0.01, train_mode=True):\n",
    "    \"\"\"Builds a charRNN model with variable layer size, number of layers, droupout, learning rate, and a training mode.\"\"\"\n",
    "    if train_mode:\n",
    "        stateful = False\n",
    "        input_shape = (None, input_length)\n",
    "    else:\n",
    "        stateful = True\n",
    "        input_shape = (1, input_length)\n",
    "    \n",
    "    # Input embedding\n",
    "    model.add(Embedding(vocab_size, layer_size, input_length=input_length, batch_input_shape=input_shape))\n",
    "              \n",
    "    # LSTM layers + 1\n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(LSTM(layer_size, return_sequences=True, stateful=stateful))\n",
    "    \n",
    "    # Final LSTM layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(layer_size, stateful=stateful))\n",
    "\n",
    "    # Project back to vocabulary\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(lr=lr))\n",
    "    model.summary()\n",
    "\n",
    "# m = Sequential()\n",
    "# model_maker(m, layer_size=128, vocab_size=vocabulary_size, input_length=30, train_mode=True)\n",
    "# m.fit(X, y, batch_size=64, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
