{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trained on 1MB of Shakespeare.\n",
    "- Outputs \"fake\" Shakespeare.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Shakespeare corpus\n",
    "- Give each leter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 12106\n",
      "total chars: 55\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "# text = open(\"tiny-shakespeare.txt\").read().lower()\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into sequences of 40 characters.\n",
    "- Change indexes into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 4019\n",
      "Done converting y to one-hot.\n",
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (4019, 50)\n",
      "y shape: (4019, 55)\n",
      "Vocabulary of characters: 55\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 50\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "X = np.zeros((len(sentences), maxlen), dtype=int)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    X[i] = np.array(map((lambda x: char_indices[x]), sentences[i]))\n",
    "    y[i, char_indices[next_chars[i]]] = True\n",
    "print(\"Done converting y to one-hot.\")\n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Input layer is an Embedding to convert from indices to a vector encoding automatically (common trick - but does it work?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 128)           7040      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                7095      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 145,719.0\n",
      "Trainable params: 145,719.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, 128, input_length=maxlen))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocabulary_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model.summary()\n",
    "\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1, 128)            7040      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 55)                7095      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 145,719.0\n",
      "Trainable params: 145,719.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4019/4019 [==============================] - 7s - loss: 2.4914     \n",
      "Epoch 2/20\n",
      "4019/4019 [==============================] - 7s - loss: 2.2794     \n",
      "Epoch 3/20\n",
      "4019/4019 [==============================] - 7s - loss: 2.1213     \n",
      "Epoch 4/20\n",
      "4019/4019 [==============================] - 7s - loss: 1.9726     \n",
      "Epoch 5/20\n",
      "4019/4019 [==============================] - 7s - loss: 1.8326     \n",
      "Epoch 6/20\n",
      "4019/4019 [==============================] - 7s - loss: 1.6728     \n",
      "Epoch 7/20\n",
      "4019/4019 [==============================] - 7s - loss: 1.5252     \n",
      "Epoch 8/20\n",
      "4019/4019 [==============================] - 8s - loss: 1.3691     \n",
      "Epoch 9/20\n",
      "4019/4019 [==============================] - 8s - loss: 1.1833     \n",
      "Epoch 10/20\n",
      "4019/4019 [==============================] - 8s - loss: 1.0277     \n",
      "Epoch 11/20\n",
      "4019/4019 [==============================] - 8s - loss: 0.8812     \n",
      "Epoch 12/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.7468     \n",
      "Epoch 13/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.6268     \n",
      "Epoch 14/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.5222     \n",
      "Epoch 15/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.4384     \n",
      "Epoch 16/20\n",
      "4019/4019 [==============================] - 8s - loss: 0.3829     \n",
      "Epoch 17/20\n",
      "4019/4019 [==============================] - 8s - loss: 0.3420     \n",
      "Epoch 18/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.2935     \n",
      "Epoch 19/20\n",
      "4019/4019 [==============================] - 7s - loss: 0.2588     \n",
      "Epoch 20/20\n",
      "4019/4019 [==============================] - 8s - loss: 0.2350     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11068c490>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model.\n",
    "model.fit(X, y, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras-shakespeare-LSTM-model-emb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras-startrek-LSTM-model-emb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 128)           7040      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                7095      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 145,719.0\n",
      "Trainable params: 145,719.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters.\n",
    "\n",
    "### Make a Decoder model\n",
    "\n",
    "- Needs input length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (1, 1, 128)               7040      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (1, 128)                  131584    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (1, 55)                   7095      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (1, 55)                   0         \n",
      "=================================================================\n",
      "Total params: 145,719.0\n",
      "Trainable params: 145,719.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dec = Sequential()\n",
    "model_dec.add(Embedding(vocabulary_size, 128, input_length=1, batch_input_shape=(1,1)))\n",
    "model_dec.add(LSTM(128, stateful=True))\n",
    "model_dec.add(Dense(vocabulary_size))\n",
    "model_dec.add(Activation('softmax'))\n",
    "model_dec.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = 'keras-shakespeare-lstm-model-emb.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-529aa7b0a8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras-shakespeare-LSTM-model-emb.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# instantiate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/travis/build/MacPython/h5py-wheels/h5py/h5py/_objects.c:2687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/travis/build/MacPython/h5py-wheels/h5py/h5py/_objects.c:2645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/Users/travis/build/MacPython/h5py-wheels/h5py/h5py/h5f.c:1933)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = 'keras-shakespeare-lstm-model-emb.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model_train = load_model(\"keras-shakespeare-LSTM-model-emb.h5\")\n",
    "model_dec.set_weights(model_train.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  be not afraid of greatness: some are born great, s\n",
      "Generated:  be not afraid of greatness: some are born great, since i have be prepence an it master heaven\n",
      "the record own therefore the down an an heart\n",
      "that thee with the dame hearts you to will it the percomes would boldness heart on her have my tower her.\n",
      "\n",
      "secong shall the capetis:\n",
      "what he may man;\n",
      "and the stand an earth,\n",
      "and i the bantent of the man to how the mannte that a prepenting of how he the dead heart i dienter the prepain of deade and men to be have my grace of the head of my beace of him in heaving head's the heaven and the mack the slempence\n",
      "the will the live them.\n",
      "\n",
      "shecinius:\n",
      "when the from the montague that i that the made.\n",
      "\n",
      "petruchio:\n",
      "and in deady.\n",
      "\n",
      "petruchio:\n",
      "i with the man must it is the sent the world him diend the drispite well the head the with the shall is heart:\n",
      "im would the death the warwick.\n",
      "\n",
      "petruchio:\n",
      "and it there to with her have my richard an on the come, done thou did a traity heaving in heart the man with the shall the caperce\n",
      "of my dich with the diend did well.\n",
      "\n",
      "lady brother:\n",
      "my bold of head her go himpt an it not \n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"keras-shakespeare-LSTM-model-emb.h5\")\n",
    "quote = \"Be not afraid of greatness: some are born great, some achieve greatness, and some have greatness thrust upon them.\"\n",
    "quote = quote.lower()\n",
    "\n",
    "def sample_model(seed, length=400):\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:50]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array(map((lambda x: char_indices[x]), sentence))\n",
    "        x = np.reshape(x,(1,50))\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)\n",
    "\n",
    "sample_model(quote, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[random.randint(0,vocabulary_size-1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the prediction model\n",
    "model_train = load_model(\"keras-startrek-LSTM-model-emb.h5\")\n",
    "model_dec.set_weights(model_train.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  c\n",
      "Generated:  churation send of hold\n",
      "the chation\n",
      "dusutht wod deather\n",
      "deatherd\n",
      "the wriand of the tho wrichture \n",
      "the mater sqiin saure the death   \n",
      "rears fot (par's of erth  par's of dove\n",
      "strdame\n",
      "endarprise  \n",
      "the matin sury the wration\n",
      "duseather ar therd part one \n",
      "brese   \n",
      "the 3rations \n",
      "imate triny ii   \n",
      "counter  \n",
      "the armaphuess   \n",
      "onerpitice   \n",
      "the warllion   \n",
      "the sward llong leath \n",
      "eedond  \n",
      "chations \n",
      "imate dirt ii\n",
      "the wroundlllllling ching gameng \n",
      "brese ii   \n",
      "a the dratien   \n",
      "the empersicy   \n",
      "the wark for toorrfronser arter shar   \n",
      "the fold   \n",
      "afir   \n",
      "rising of the end of meas\n",
      "hold sury the the tho wroundiand shild sury the wrophope  \n",
      "the emperce stiphold  \n",
      "rears   \n",
      "farface \n",
      "the chusesion \n",
      "ching part one \n",
      "the wriakerpare in the defor \n",
      "undatter sury the wroght (part 2emations \n",
      "the thunter ar'sion \n",
      "breture  \n",
      "the death   \n",
      "rising of the the kerphation\n",
      "durture sury the chake  \n",
      "horker   \n",
      "prosticy \n",
      "bod tronge hold  \n",
      "relf (part 2i   \n",
      "ymar's of mina   \n",
      "the warn surviind \n",
      "chinise  \n",
      "the jent orevics  \n",
      "the writy\n"
     ]
    }
   ],
   "source": [
    "# model_train = load_model(\"keras-startrek-LSTM-model-emb.h5\")\n",
    "# model_dec.set_weights(model_train.get_weights())\n",
    "\n",
    "def sample_model(seed, model_name, length=400):\n",
    "    generated = ''\n",
    "    sentence = seed.lower()[:]\n",
    "    generated += sentence\n",
    "    print(\"Seed: \", generated)\n",
    "    \n",
    "    for i in range(length):\n",
    "        x = np.array(map((lambda x: char_indices[x]), sentence))\n",
    "        x = np.reshape(x,(1,1))\n",
    "        preds = model_name.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    print(\"Generated: \", generated)\n",
    "\n",
    "sample_model(indices_char[random.randint(0,vocabulary_size-1)], model_dec, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
